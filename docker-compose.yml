version: "3.9"

services:
  kafka_ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka_ui
    environment:
      KAFKA_CLUSTERS_0_NAME: "scm-cluster"
      # Use the internal Docker DNS name for the Kafka broker so kafka-ui
      # can reach Kafka over the Docker network (avoids hairpin/NAT issues
      # when EXTERNAL_KAFKA_HOST is a public IP not present on the host).
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: "kafka:9092"
    ports:
      - "8086:8080"
    restart: unless-stopped



  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U airflow" ]
      interval: 5s
      timeout: 5s
      retries: 5

  zookeeper:
    image: bitnami/zookeeper:3.9
    environment:
      ALLOW_ANONYMOUS_LOGIN: "yes"
    ports:
      - "2181:2181"
    healthcheck:
      test: [ "CMD-SHELL", "echo ruok | nc localhost 2181" ]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - zookeeper_data:/bitnami

  kafka:
    image: bitnami/kafka:3.7
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_ENABLE_KRAFT: "no"
      KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CFG_NODE_ID: "1"
      KAFKA_CFG_LISTENERS: PLAINTEXT://:9092
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: "true"
      ALLOW_PLAINTEXT_LISTENER: "yes"
    ports:
      - "9092:9092"
    healthcheck:
      test: [ "CMD", "echo", "ok" ]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - kafka_data:/bitnami

  scm_api:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: scm_api
    ports:
      - "8000:8000"
    volumes:
      - ./airflow/output:/app/data

  airflow-init:
    build: ./airflow
    depends_on:
      postgres:
        condition: service_healthy
    user: "${AIRFLOW_UID:-1000}:0"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW_UID=${AIRFLOW_UID:-1000}
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/data:/opt/airflow/data
      - ./airflow/requirements.txt:/requirements.txt
      - ./.env:/opt/airflow/.env
      - ./airflow/output:/opt/airflow/output
      - ./airflow/logs:/opt/airflow/logs
    command: >
      bash -c " airflow db init && airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || true "

  airflow-webserver:
    build: ./airflow
    depends_on:
      postgres:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    restart: always
    user: "${AIRFLOW_UID:-1000}:0"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW_UID=${AIRFLOW_UID:-1000}
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    ports:
      - "8083:8080"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/data:/opt/airflow/data
      - ./airflow/requirements.txt:/requirements.txt
      - ./.env:/opt/airflow/.env
      - ./airflow/output:/opt/airflow/output
      - ./airflow/logs:/opt/airflow/logs
    command: airflow webserver

  airflow-scheduler:
    build: ./airflow
    depends_on:
      postgres:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    restart: always
    user: "${AIRFLOW_UID:-1000}:0"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW_UID=${AIRFLOW_UID:-1000}
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/data:/opt/airflow/data
      - ./airflow/requirements.txt:/requirements.txt
      - ./.env:/opt/airflow/.env
      - ./airflow/output:/opt/airflow/output
      - ./airflow/logs:/opt/airflow/logs
    command: airflow scheduler

volumes:
  postgres_data:
  zookeeper_data:
  kafka_data:
  airflow_output:
  airflow_logs:
